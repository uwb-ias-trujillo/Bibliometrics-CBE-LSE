---
title: "CBE-LSE Bibliometric Analysis"
author: "Caleb Trujillo, Darcie Nelson, Rachel Kudlacz, Germaine Ng"
date: "10/18/2021"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require("devtools")
require("rgexf")
require("bibliometrix")
require("igraph")
require("tidyverse")
require("xtable")
#devtools::install_github("massimoaria/bibliometrix")

devtools::install_github("wmurphyrd/fiftystater")
library(bibliometrix)
library(tidyverse)
library(networkD3)
library(rgexf)
library(igraph)
library(xtable)
library(readxl)
library(scales)
library(ggplot2)
library("fiftystater")
```

##Introduction

There has tremendous growth in the area undergraduate biology research over the last two decades. This study attempts to summarize and analyze the progress of this growth for the journal of *CBE-LSE*. 

### Summary of initial data set

```{r dataset}
txt <- c("rawdata/CBE-LSE-2010-2020/WOS-CBELSE-2010-2020-1-500.txt",
         "rawdata/CBE-LSE-2010-2020/WOS-CBELSE-2010-2020-501-853.txt")
data <- convert2df(file = txt, dbsource = 'wos', format = "plaintext")
results <- biblioAnalysis(data, sep = ";")

theme_default <- theme(
    plot.caption = element_text(hjust = 0, face= "italic"),
    plot.title.position = "plot",
    plot.caption.position =  "plot",
    panel.background = element_rect(
      fill = "#F2F2F2"),
    panel.grid = element_line(size = .25, color = "#99CCCC"),
    axis.ticks = element_line(color = "#F2F2F2"),
    legend.key = element_rect(color = "#F2F2F2"),
    legend.background = element_rect(
      fill = "#F2F2F2"),
    legend.position = "top",
    plot.background = element_rect(
      fill = "#F2F2F2")
    )
```

After results are processed, these are stored as data tables for information reporting. 

```{r biblio}
options(width=100)

S <- summary(object = results, pause = FALSE)
S
plot(x=results, k=10, pause=F)

S$MainInformationDF

dir.create("tables")
write.csv(file = "tables/keywords.csv",as.data.frame(results$ID[1:20]))

write.csv(file = "tables/Maininformation.csv",S$MainInformationDF)

write.csv(file = "tables/ArticlesYears.csv",S$AnnualProduction)

write.csv(file = "tables/MostCitedPapers.csv",S$MostCitedPapers)

write.csv(file = "tables/MostProdAuthors.csv", S$MostProdAuthors)

write.csv(file = "tables/Universities.csv", results$Affiliations)
```
## Research Questions

### Basic overview of the field

```{r overview}
colnames(S$AnnualProduction) <- make.names(colnames(S$AnnualProduction))

ggplot(data = S$AnnualProduction, mapping = aes(x = Year..., y = Articles, group = 1)) +
  geom_line(stat = "identity", color = "#F26E50", size = 1.5)+
  theme_dark()+
  theme_default +
  labs(
    title = "Annual productivity by articles published per year",
    x = NULL,
    y = NULL
  )
ggsave("AnnualProductivity.jpg", device = "jpeg")
xtable(S$MainInformationDF)
```


##Authoring

```{r author productivity}
authors=gsub(","," ",names(results$Authors))

indices <- Hindex(data, field = "author", elements=authors, sep = ";", years = 50)

indices$H %>%
  arrange(desc(NP))

as_tibble(results$Authors)


inner_join(as_tibble(results$Authors),indices$H)

indices$H

#authorProdOverTime(data, k = 10, graph = TRUE)
  
ggplot(indices$H,aes(size = NP, y = h_index)) + 
  geom_jitter(aes(alpha = 0.1)) +
  geom_text(aes(label = Element), check_overlap = TRUE) #+
  #scale_x_log10()   #geom_smooth()
```

### Affiliations
```{r affiliations, echo=FALSE}

#Joining files
msidata <- read_excel("rawdata/2020eligibilitymatrix.xlsx", 
    skip = 10)
affiliations <- read_excel("tables/UnivIndex.xlsx")
msiuniv <- left_join(affiliations, msidata) %>%
  filter(OPEID != "NA")

#Tables
msistates <- msiuniv %>%
  group_by(St) %>%
  summarize(n = n()) %>%
  filter(!(St %in% c("DC", "MH", "PR", "VI", "GU"))) %>% 
  rename(states = St, Assault = n)
view(msistates)

msistates$states <- state.name[match(msistates$states,state.abb)]

data("fifty_states")

affiliationMap <- ggplot(msistates, aes(map_id = states)) + 
  geom_map(aes(fill = Assault),  color= "black", map = fifty_states) + 
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  #geom_text(data = fifty_states %>%
   #           group_by(id) %>%
    #          summarise(lat = mean(c(max(lat), min(lat))),
     #                   long = mean(c(max(long), min(long)))) %>%
      #        mutate(St = id) %>%
       #       left_join(msistates, by = "St"), aes(x = long, y = lat, label = n))+
  scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "") + theme(legend.position = "bottom", 
                               panel.background = element_blank())

affiliationMap

ggplot(data= msistates, aes(map_id = state)) + 
  geom_map(aes(fill = Assault),  color= "black", map = fifty_states) + 
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  geom_text(data = fifty_states %>%
              group_by(id) %>%
              summarise(lat = mean(c(max(lat), min(lat))),
                        long = mean(c(max(long), min(long)))) %>%
              mutate(state = id) %>%
              left_join(msistates, by = "state"), aes(x = long, y = lat, label = Assault ))+
  scale_x_continuous(breaks = NULL) + scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "") + theme(legend.position = "bottom", 
                               panel.background = element_blank())



msiuniv$`Eligible/ Current Grant` <- as.factor(msiuniv$`Eligible/ Current Grant`)
msieligible <- msiuniv %>%
  group_by(`Eligible/ Current Grant`) %>%
  summarize(n = n())
view(msieligible)

msiuniv$`Type & Control` <- as.factor(msiuniv$`Type & Control`)
msitype <- msiuniv %>%
  group_by(`Type & Control`) %>%
  summarize(n = n())
view(msitype)

temp <- msiuniv %>%
  mutate_if(is.numeric,as.factor)%>%
  mutate_if(is.character,as.factor)%>%
  select(`Institution Name`,`AANAPISI`, `AANAPISI F`,`ANNH`,`ANNH F`,`HBCU`,`HBCU Masters`	, HBGI,HSI,`HSI STEM`,NASNTI, `NASNTI F` ,`PBI F`,`PBI A`,PPOHA,SIP,TCCU) %>%
  pivot_longer(cols = !`Institution Name`) %>%
  mutate(eligibility = if_else(value == 1 | value == 2| value == 3, "Ineligible", "NA")) %>%
  mutate(eligibility = if_else(value == 4 | value == '4R' |value == 5 | value == '5R', "Eligible or potentially eligible", eligibility))%>%
  mutate(eligibility = if_else(value == 6, "Current grantee", eligibility)) %>%
  mutate(eligibility = if_else(value == 0, "Undetermined", eligibility)) %>%
  group_by(name,eligibility)%>%
  summarize(n=n())%>%
  mutate(perc = round(n/sum(n),3))

msisummary_n <- temp%>%
  select(!perc)%>%
  pivot_wider(names_from = name, values_from = c(n))
view(msisummary_n)

msisummary_perc <- temp%>%
  select(!n)%>%
  mutate(perc = label_percent()(perc)) %>% 
  pivot_wider(names_from = name, values_from = c(perc))
view(msisummary_perc)

temp %>% 
  filter(eligibility != "Ineligible" & eligibility != "Undetermined") %>%
  ggplot(aes(x=reorder(name, perc), y=perc, fill = eligibility)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent) +
  coord_flip() + 
  labs(
    title = "Percent of affilitations by Minority Serving Institution program eligibilty",
    x = NULL,
    y = NULL
  ) +
  theme_dark()+
  scale_fill_manual(values = c("#F26E50", "#F2A679"))+
  theme_default

  #mutate(status = if_else(value == TRUE, "Eligible or current grantee",  NA, status ==                     if_else(value == FALSE,"Not eligible or potentially eligible", NA)))

#Eligibility tables
msiaanapisi <- msiuniv %>%
  group_by(AANAPISI) %>%
  summarize(n = n())
view(msiaanapisi)

msiaanapisif <- msiuniv %>%
  group_by(`AANAPISI F`) %>%
  summarize(n = n())
view(msiaanapisif)

msiannh <- msiuniv %>%
  group_by(ANNH) %>%
  summarize(n = n())
view(msiannh)

msiannh <- msiuniv %>%
  group_by(ANNH) %>%
  summarize(n = n())
view(msiannh)

msiannhf <- msiuniv %>%
  group_by(`ANNH F`) %>%
  summarize(n = n())
view(msiannhf)

msihbcu <- msiuniv %>%
  group_by(HBCU) %>%
  summarize(n = n())
view(msihbcu)

msihbcumasters <- msiuniv %>%
  group_by(`HBCU Masters`) %>%
  summarize(n = n())
view(msihbcumasters)

msihbgi <- msiuniv %>%
  group_by(HBGI) %>%
  summarize(n = n())
view(msihbgi)

msihsi <- msiuniv %>%
  group_by(HSI) %>%
  summarize(n = n())
view(msihsi)

msihsistem <- msiuniv %>%
  group_by(`HSI STEM`) %>%
  summarize(n = n())
view(msihsistem)

msimseip <- msiuniv %>%
  group_by(MSEIP) %>%
  summarize(n = n())
view(msimseip)

msinasnti <- msiuniv %>%
  group_by(NASNTI) %>%
  summarize(n = n())
view(msinasnti)

msinasntif <- msiuniv %>%
  group_by(`NASNTI F`) %>%
  summarize(n = n())
view(msinasntif)

msipbif <- msiuniv %>%
  group_by(`PBI F`) %>%
  summarize(n = n())
view(msipbif)

msipbia <- msiuniv %>%
  group_by(`PBI A`) %>%
  summarize(n = n())
view(msipbia)

msippoha <- msiuniv %>%
  group_by(PPOHA) %>%
  summarize(n = n())
view(msippoha)

msisip <- msiuniv %>%
  group_by(SIP) %>%
  summarize(n = n())
view(msisip)

msitccu <- msiuniv %>%
  group_by(TCCU) %>%
  summarize(n = n())
view(msitccu)

```


### Social Network Analysis (SNA) of co-authorship: What social structures are organizing co-authorship? 
Rachel Kudlacz 
This is the placeholder for the question about the social struction of co-authorship the among the CBE-LSE authors. A social network analysis approach was used...
Text to introduce the script and outputs
```{r co-authorship,echo=FALSE}
#INSERT FUNCTION FOR CREATING DOCUMENT COCITATION NETWORK using 'data' file
# Create a Social Network Analysis(SNA) Network from Co-Citation Network
CoAMatrix <- biblioNetwork(data, analysis = "collaboration", network = "authors", sep = ";")

# Plot the network - look into SNA application
CoANet <- networkPlot(CoAMatrix, n = dim(CoAMatrix)[1], Title = "Social Network Analysis", type = "auto", size=0.1, remove.multiple=FALSE, labelsize = 1, edgesize = 1, edges.min = 1, label.n = 10, cluster = "louvain", remove.isolates = TRUE)

plot(CoANet$graph, vertex.label.family = "Helvetica")

write_graph(CoANet$graph,"Gephi files/CBE_LSE_Co-authorshipedge1.graphml", c("graphml"))

#CoANet2 <- networkPlot(CoAMatrix, n = dim(CoAMatrix)[1], Title = "Social Network Analysis", type = "auto", size=0.1, remove.multiple=FALSE, labelsize = 1, edgesize = 1, edges.min = 3, label.n = 10, cluster = "louvain", remove.isolates = TRUE)

#plot(CoANet2$graph, vertex.label.family = "Helvetica")

#write_graph(CoANet2$graph,"CBE_LSE_Co-authorshipedge3.graphml", c("graphml"))
```

Text to explain what is shown in the figures.

### What are the collaborative connections between institutions?

Germaine Ng 

This is the placeholder for the question about collaborations between different universities (institutions)
Text to introduce the script and outputs

```{r institution productivity}
Affiliation=results$Affiliations[1:20]
Affiliation

Aff_Freq=results[["Aff_frac"]] %>%
  arrange(desc(Frequency))%>%
  top_n(10)
Aff_Freq

summary(results$Affiliations)
```


```{r collaborative, echo=FALSE}
#INSERT FUNCTION FOR CREATING INSTITUTIONAL NETWORK using 'data' file
#UNdata <- metaTagExtraction(data, Field = "AU_UN", sep = ";")

UniNetMatrix <- biblioNetwork(data, analysis = "collaboration", network = "universities", sep = ";")

# Plot the network

Uninet=networkPlot(UniNetMatrix, n = dim(UniNetMatrix)[1], Title = "Top 20 University Collaborations", type = "auto", size.cex =TRUE, remove.multiple=FALSE, remove.isolates = TRUE, labelsize=0.7,edgesize = 5, edges.min = 3)

plot(Uninet$graph, vertex.label.family = "Helvetica")

head(Uninet$nodeDegree) # Top six universities by degree of publications with other universities
write_graph(Uninet$graph,"Gephi files/CBE_LSE_Universityedge3.graphml", c("graphml"))


Uninet2=networkPlot(UniNetMatrix, n = dim(UniNetMatrix)[1], Title = "Top  University Collaborations", type = "auto", size.cex =TRUE, remove.multiple=FALSE, remove.isolates = TRUE, labelsize=0.7,edgesize = 5, edges.min = 1)

plot(Uninet2$graph, vertex.label.family = "Helvetica")
write_graph(Uninet2$graph,"Gephi files/CBE_LSE_Universityedge1.graphml", c("graphml"))

ggplot((Aff_Freq)) +
         geom_col(aes(x = reorder(Affiliation, Frequency), y = Frequency)) +
  coord_flip() +
  theme_bw()
       
```

### What is the intellectual structures? Document co-citation network and topic analysis

Darcie Nelson
```{r citation}
library(stringdist)
library(stringr)
library(stringi)
library(plyr)
library(dplyr)
library(magrittr)
library(broom)
library(lazyeval)
library(tidyr)
library(reshape2)
library(data.table)

#citations

# load functions
  source("cleaningfunctions/citation_functions.R")


# Extract citations from WOS list
    work_data <- as.data.frame(extract_citation(data, "CR"))
    #work_data$label <- as.character(work_data$label)
    work_data$L1<- as.factor(work_data$L1)
    work_data$index<-as.factor( work_data$index)

# Standardize the data--------------------------------------------------------------------
   std_data <- standardize(work_data)

# show authors who are longer than 50 characters
   author_temp <- std_data %>%
        select(authors) %>%
        filter(nchar(authors) > 50)

# clean and standardize author names -----------------------------------------------------

# Run fuzzy match function on a .2 threshold

    std_data$authorBlock <- fuzzy_match(std_data$authors, .1, std_data$authors)

    
   # look at author clusters
    author_merges <- std_data %>%
      group_by(authorBlock) %>%
      dplyr::summarise(count = n()) %>%
      filter(count > 15) %>%
      arrange(desc(count))


    # Run the clustering algorithm again to recluster top merge
    # get the top merged author
    name <- author_merges[1, ][[1]]

    std_data2 <- std_data %>%
      filter(authorBlock == name) %>%
      mutate(authorBlock = fuzzy_match(authors, .08, authors))

    std_data3 <- std_data %>%
      filter(authorBlock != name) %>%
      bind_rows(std_data2)

    std_data4 <- std_data3 %>%
      filter(authorBlock == name) %>%
      mutate(authorBlock = fuzzy_match(authors, .05, authors))

    std_data5 <- std_data3 %>%
      filter(authorBlock != name) %>%
      bind_rows(std_data4)

#Add specific criteria for problematic author names
    std_data5$authorBlock[grep("assaraf", std_data5$authorBlock)]


# Run clustering algorithm----------------------------------------------------------------
    books <- std_data5 %>%
        group_by(authorBlock, documentName, documentYear) %>%
        filter(type == "book") %>%
        mutate(mergedLabel = fuzzy_match(cleanLabel, .05, cleanLabel))


    articles <- std_data5 %>%
        group_by(authorBlock, documentName, documentYear) %>%
        filter(type == "article") %>%
        mutate(mergedLabel = fuzzy_match(cleanLabel, .01, cleanLabel))

        clean_data <- rbind(books, articles)


# create the flat data file
    
    flat_data<- as.data.table(clean_data)[, toString(paste0(mergedLabel,collapse = ";")), by = list(L1)]



# make sure to unwrap this again to check if it was wrapped properly
    rownames(flat_data) <- as.character(flat_data$L1)
                                         
    flat_data2 <- inner_join(data, flat_data, by = c("SR" = "L1"))
    flat_data2$CR <- flat_data2$V1
# find the similarity  of the merges------------------------------------------------------

    clean_data <- clean_data %>%
        mutate(jwSimilarity = calc_jw(cleanLabel, mergedLabel))


# plot------------------------------------------------------------------------------------

    merged <- clean_data %>%
        filter(jwSimilarity < 1)


    hist(round(merged$jwSimilarity, 3),
         xlab = "jw similarity distance",
         main = "Freq Merges by similarity distance \n with year and document type boundary")

# save the data------------------------------------------------------------------------------------
    write.csv(clean_data, "WOS_nodeList.csv", row.names = FALSE)
    write.csv(flat_data2, "WOS_clean.csv", row.names = FALSE)

CR <- citations(data, field = "article", sep = ";")
CRtable <-cbind(CR$Cited[1:20])
CRtable
CR2 <- citations(flat_data2, field = "article", sep = ";")
CR2table <-cbind(CR2$Cited[1:20])
CR2table
write.csv(file = "Citations.csv",CR2table)

sourcestable <-cbind(summary(factor(CR$Source))
[1:10])
sourcestable

write.csv(file = "Sources.csv",sourcestable)

    
    
```

```{r DCA, echo=FALSE, fig.width = 50, fig.asp = .618}

#DOCUMENT COCITATION NETWORK using 'data' file
# Create a co-citation network
DCAMatrix <- biblioNetwork(flat_data2, analysis = "co-citation", network = "references", sep = ";")


# Plot the network
DCA = networkPlot(DCAMatrix, n = dim(DCAMatrix)[1], Title = "Co-Citation Network", type = "auto", size.cex = TRUE, remove.multiple=FALSE, labelsize = 10, edgesize = 5, edges.min = 4, label.n = 30, cluster = "louvain", remove.isolates = TRUE, label.cex = TRUE)

plot(DCA$graph, vertex.label.family = "Helvetica")
names(DCA$nodeDegree["american association 2011-1"])<- "AAAS 2011"
noded<-DCA$nodeDegree

write_graph(DCA$graph,"Gephi files/CBE_LSE_DCAedge4.graphml", c("graphml"))
```

```{r bibliographic coupling}
rownames(flat_data2) <- rownames(data)
BC <- biblioNetwork(flat_data2, analysis = "coupling", network = "references", sep = ";")

BCnet = networkPlot(BC, n = dim(BC)[1], Title = "Bibliographic Coupling", type = "auto", size.cex = TRUE, remove.multiple=FALSE, labelsize = 1, edgesize = 5, edges.min = 4, label.n = 30, cluster = "louvain", remove.isolates = TRUE, label.cex = TRUE)

ggsave("bibliographiccoupling4.png", plot = BCnet$graph_terms, device = "png")

write_graph(BCnet$graph,"Gephi files/CBE_LSE_BC4.graphml", c("graphml"))
```

```{r topics and keywords}
CS <- conceptualStructure(data,field ="ID", method = "MCA", minDegree=19, clust= 4 ,k.max=20, stemming=TRUE, labelsize=10, documents=10)

#CS4 <- conceptualStructure(data,field ="ID", method = "MCA", minDegree=6, clust= "auto" ,k.max=20, stemming=TRUE, labelsize=4, documents=10)

ggsave("ConceptualStructure.png", plot = CS$graph_terms, device = "png")
```
